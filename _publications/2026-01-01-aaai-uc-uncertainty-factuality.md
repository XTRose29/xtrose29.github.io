---
title: "Can You Trust What I Think? Analyzing and Improving Verbalized Uncertainty and Factuality in Reasoning-Based Large Language Models"
collection: publications
category: conferences
permalink: /publication/2026-01-01-aaai-uc-uncertainty-factuality
excerpt: 'Accepted for presentation at AAAI-26 Undergraduate Consortium.'
date: 2026-01-01
venue: 'AAAI-26 Undergraduate Consortium'
paperurl: 
citation: 'Tianruo Rose Xu, Anirudh Atmakuru, Priyan Pattnayak, Tanya Goyal. Can You Trust What I Think? Analyzing and Improving Verbalized Uncertainty and Factuality in Reasoning-Based Large Language Models. AAAI-26 Undergraduate Consortium, Singapore, January 2026.'
share: false
hide_auto_published: true
---

## Abstract

Reasoning-based large language models often produce natural-language thinking traces with their answers, but it remains unclear whether the verbalized uncertainties expressed in thinking traces faithfully reflect model's knowledge. We study this question on long-form, knowledge-intensive biography generation. Our pipeline decomposes thinking traces and responses into atomic facts, filters out planning content, labels factual reasoning by certainty, and aligns response facts to their supporting reasoning, enabling plan-based filtering, self-verification, and a classifier that predicts factuality from facts and associated reasoning. Preliminary results suggest that high-certainty reasoning is more likely to be included and correct and that structured use of these signals can improve factuality, though broader validation across models and dataset will be needed.

Published in AAAI-26 Undergraduate Consortium and presented at both the Undergraduate Consortium and Main Track Session (Singapore, January 2026).

